---
title: "Enhancing the Perception Ability of VLM through Reinforcement Learning via Data Engine"
excerpt: "Research on improving VLM visual perception using synthetic data engines and reinforcement learning. Targeted enhancement of fine-grained visual understanding through cost-effective, automatically verifiable QA tasks."
collection: portfolio
date: 2025-05-01
category: research
---
 
Tsinghua University  
May 2025  

*Note: Due to company policy restrictions, this research cannot be published independently on arXiv. This work is documented in blog format.*

## TL;DR

**Perceptual capability is critical for Vision-Language Models (VLMs).** However, current VLM training efforts primarily focus on various multimodal reasoning or generation tasks, with relatively little attention paid to improving the model's perception ability. This is largely because perception skills are difficult to train directly through supervised fine-tuning (SFT). Recently, reinforcement learning (RL) has emerged as a promising alternative.

Yet acquiring high-quality perception data—either from the internet or via human annotation—is expensive and often inconsistent. In this blog, we explore an alternative approach: using *Data Engines* to construct synthetic data tailored for reinforcement learning training of VLMs. This method is cost-effective, ensures correctness of the data, and offers full flexibility in data customization.

**Full Research Blog**: [Enhancing the Perception Ability of VLM through Reinforcement Learning via Data Engine](https://www.notion.so/Enhancing-the-Perception-Ability-of-VLM-through-Reinforcement-Learning-via-Data-Engine-1aca1e0d824c80898693ed5fec3348ac)