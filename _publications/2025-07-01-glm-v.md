---
title: "GLM-4.1V&4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning"
collection: publications
permalink: /publication/2025-07-01-glm-v
excerpt: 'Contributor, Z.ai, GLM-V Team'
date: 2025-07-01
venue: 'Hugging Face'
paperurl: 'https://huggingface.co/papers/2507.01006'
citation: 'Your Name, GLM-4.1V&4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning, Z.ai, 2025.'
---

**Reinforcement Learning with Curriculum Sampling:** Co-developed RLCS to scale long-chain multimodal reasoning by gradually increasing task difficulty and stabilizing reward optimization across visionâ€“language tasks.

**Model & Evaluation:** Helped train and tune GLM-4.1V-Thinking (9B) and GLM-4.5V (106B), achieving SOTA on 42 public VL benchmarks, surpassing Qwen2.5-VL-72B on 29 tasks and ranking #1 on Hugging Face trending models.

[Download paper here](https://huggingface.co/papers/2507.01006)

Recommended citation: Your Name (2025). "GLM-4.1V&4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning." *Hugging Face*. https://huggingface.co/papers/2507.01006.