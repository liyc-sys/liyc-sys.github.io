---
title: "GLM-4.1V&4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning"
collection: publications
permalink: /publication/2025-07-01-glm-v
excerpt: 'Contributor, Z.ai, GLM-V Team'
date: 2025-07-01
venue: 'Technical Report'
paperurl: 'https://huggingface.co/papers/2507.01006'
---

**Reinforcement Learning with Curriculum Sampling:** Co-developed RLCS to scale long-chain multimodal reasoning by gradually increasing task difficulty and stabilizing reward optimization across visionâ€“language tasks.

**Model & Evaluation:** Helped train and tune GLM-4.1V-Thinking (9B) and GLM-4.5V (106B), achieving SOTA on 42 public VL benchmarks, surpassing Qwen2.5-VL-72B on 29 tasks and ranking #1 on Hugging Face trending models.

[Download paper here](https://huggingface.co/papers/2507.01006)

**Open Source Model:** The GLM-4.5V model is available on Hugging Face: [https://huggingface.co/zai-org/GLM-4.5V](https://huggingface.co/zai-org/GLM-4.5V)